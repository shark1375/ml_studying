{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. ML시스템의 종류\n",
    "- 사람의 감독 하에 있는 훈련인지 아닌지 -> 지도/비지도\n",
    "- 실시간으로 점진적 학습을 하는지 -> 온라인/배치\n",
    "- 알고 있는 포인트 vs 새 포인트인지, 훈련 set에서 패턴을 통해 예측 모델을 만드는 건지 -> 사례기반/모델기반"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1. 지도/비지도\n",
    "### Supervised Learning\n",
    "- 훈련데이터에 Lable이 포함되어있음\n",
    "- 1) 분류가 전형적인 지도학습 (ex : 스팸필터)\n",
    "- 2) 예측 또한 지도학습 -> 예측 변수라 불리는 특성을 활용하여 특정 타깃 수치를 예측하는 것\n",
    "    - 회귀는 기본적으로 2)지만 로지스틱 같이 변형된 경우 1)에 활용\n",
    "- 대표적인 알고리즘들\n",
    "    - a. KNN\n",
    "    - b. Linear Regression\n",
    "    - c. Logistic Regression\n",
    "    - d. SVM\n",
    "    - e. Decison Tree & RF\n",
    "    - f. ANN\n",
    "    \n",
    "### Unsupervised Learning\n",
    "- 훈련 데이터에 레이블이 없는 것(군집화, 시각화, 차원축소_특성추출, 이상치 탐지, 연관규칙)\n",
    "- 대표적인 알고리즘들\n",
    "    - a. K-Means Clustering\n",
    "    - b. HCA : 계층 군집분석\n",
    "    - c. Expctation Maximization : 기댓값 최대화\n",
    "    - d. PCA\n",
    "    - e. Kernel PCA\n",
    "    - f. LLE : 지역적 선형 임베딩\n",
    "    - g. t-SNE(Stochastic Neighbor Embedding)\n",
    "    - h. Apriori\n",
    "    - i. Eclat\n",
    "    \n",
    "### Semi-supervised Learning\n",
    "- 레이블이 일부만 있을 수 있음\n",
    "- 일반적으로는 레이블이 아주 젖ㄱ을 것\n",
    "- ex) Google Photo Hosting Service : 군집화 하여 동일 인물을 찾고, 레이블을 추적하여 레이블링 해주는 것\n",
    "- 보통 지도학습과 비지도 학습의 조합으로 이루어져있음\n",
    "- 대표적인 알고리즘들\n",
    "    - a. DBN : Deep Belief Network - 심층 신뢰 신경망 -> 여러 겹의 제한된 볼츠만 머신(RBM)이라는 비지도 학습에 기초함\n",
    "        - RBM이 순차적으로 훈련된 다음, 지도 학습 과정을 통해 세밀하게 조정\n",
    "        \n",
    "### Reinforcement Learning\n",
    "- 아주 다른 종류의 알고리즘임\n",
    "- 학습 시스템을 Agent라고 부름\n",
    "- 환경 관찰 -> 행동 -> 보상/벌점\n",
    "    -> 시간이 흐르며 Policy를 세우고 이에 따라 최상의 전략을 학습함\n",
    "    -> 따라서 로봇을 만들기 위해서 주로 활용하며, 가장 대표적인 것이 갓파고;;;;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.2. 배치학습과 온라인 학습\n",
    "- ML 구분 기준의 다른 종류\n",
    "- 데이터 스트림으로부터 점진적으로 지속적인 학습을 하냐~ 안하냐의 차이\n",
    "\n",
    "### Batch Learning\n",
    "- 시스템이 점진적으로 학습할 수 없음\n",
    "- 가용 데이터 전부를 이용하여 훈련시켜야함\n",
    "    - 따라서, 시간과 자원을 많이 소모 -> 오프라인 수행\n",
    "    - 시스템을 훈련시키고 완성된 시스템을 데이터스트림에 노출하는 형태 -> 추가학습은 없음\n",
    "- 새로운 데이터에 적용하려면 해당 데이터와 기존의 학습데이터 전체를 긁어와서 다-시 학습시켜야하는 문제가 있음\n",
    "- 간단하고 잘 작동함 -> but 시간문제가 있음\n",
    "    - 실시간으로 데이터에 반응해야하며, 자원이 제한적인 상황에서는 능동적이고 점진적인 학습이 필요함\n",
    "    \n",
    "### Online Learning\n",
    "- 데이터를 순차적으로 미니배치라는 작은 묶음 단위로 주입 -> 시스템 훈련\n",
    "- 학습 속도가 빠르며, 비용이 적음\n",
    "- 빠른 변화에 적응하거나, 리소스가 모자란 상황에서 좋음(ex : 주식시장, 스마트폰)\n",
    "- 이 때 가장 중요한 파라미터는 Learning Rate임\n",
    "    - LR이 높음 -> 데이터에 빠르게 적응 -> but 이전의 것을 금방 잊음\n",
    "    - LR이 낮음 -> 기존 시스템에 대한 높은 관성 -> 학습 속도가 늦어지지만, 이상치에 Robust해짐\n",
    "- 온라인 학습의 가장 큰 문제는 이상 데이터에 노출될 경우, 모델의 성능이 점차 감소한다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.3. 사례기반 학습과 모델 기반 학습\n",
    "- ML 모델이 일반화되는 방법에 따라 분류할 수 있음\n",
    "- 훈련데이터에서 본 적 없는 데이터도 예측 잘할 수 있도록 일반화 되어야함.\n",
    "- 이 때 접근법이 사례기반 vs 모델 기반임\n",
    "\n",
    "### 사례기반학습\n",
    "- 시스템이 사례를 기억하여 학습 -> 유사도를 측정하여 새로운 데이터를 일반화\n",
    "- ex) 스팸메일\n",
    "- 거를 놈들은 정확히 거를 수 있음\n",
    "- 하지만, 새로운 사례에 취약할 수 있음.\n",
    "- 시나리오 기반 FDS들을 생각하면 될 것 같음\n",
    "\n",
    "### 모델기반학습\n",
    "- 샘플 -> 모델 -> 예측\n",
    "- 파라미터를 조정하며 더욱 정확한 모델을 만들어냄\n",
    "- 그 때 기반이 되는 것은 효용함수(Utility Ft = 적합도 함수_fitness Ft)나 Cost Ft임\n",
    "- 주로 머신러닝에서 활용되는 방법임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4. ML의 주요 도전 과제\n",
    "- 가장 중요한 태클은 나쁜 Alg와 나쁜 Data\n",
    "\n",
    "# 나쁜 데이터\n",
    "\n",
    "## 1.4.1. 충분하지 않은 훈련 데이터\n",
    "- 특히 복잡한 문제에서는 아직 Algorithm보다는 Data의 문제가 더 큼\n",
    "    - But 그만큼 충분한 데이터를 갖는 경우는 드물기 때문에 아이러니하게 알고리즘의 중요성이 더 커짐\n",
    "\n",
    "## 1.4.2. 대표성이 없는 훈련 데이터\n",
    "- 일반화의 문제\n",
    "- 일반화할 수 있도록 훈련 세트를 활용하는 것은 매우매우매우 중요하지만, 이게 생각보다 어려움\n",
    "    - Sampling Noise : 샘플이 작을 경우 -> 우연에 의한 대표성 없는 데이터 발생\n",
    "    - Sampling Bias : 샘플이 크더라도 편향이 발생할 수 있음\n",
    "    \n",
    "## 1.4.3. 저품질의 데이터\n",
    "- 훈련 데이터가 error, outlier, noise로 가득하다면 당연히 문제가 될 것\n",
    "    - 정제된 데이터를 만들기 위해 충분한 시간을 할애해야함\n",
    "    \n",
    "## 1.4.4. 관련 없는 특성\n",
    "- Garbage In Garbage Out\n",
    "- Feature Engineering : 훈련에 활용할 수 있는 좋은 Feature들을 추출해내는 과정\n",
    "    - Feature Selection : 가지고 있는 Feature 중 가장 유용한 Feature 선택\n",
    "    - Feature Extraction : Feature를 결합하여 더욱 유용한 Feature를 만들어냄(ex : 차원축소)\n",
    "\n",
    "# 나쁜 알고리즘\n",
    "\n",
    "## 1.4.5. 훈련데이터 과대적합\n",
    "- Overfitting\n",
    "- 훈련세트에 노이즈가 많거나, 데이터셋이 작을 경우 너무 미세한 포인트까지 잡게 됨\n",
    "    - 따라서 새로운 데이터 셋에 일반화하는 데 문제가 생김\n",
    "- 잡음의 양에 비해 모델이 너무 복잡할 때 발생하는 문제\n",
    "    - 파라미터 수가 적은 모델을 선택하거나, 훈련 피쳐를 줄이거나, 모델에 제약을 가하여 단순화\n",
    "    - 훈련 데이터를 더 많이 모으기\n",
    "    - 훈련 데이터의 노이즈 줄이기(전처리 잘하자!)\n",
    "- Regulation의 양은 hyper Parameter로 결정함\n",
    "    - Hyper Parameter는 모델이 아닌 학습 알고리즘의 Parameter\n",
    "    - 즉, 훈련 전에 이미 지정되고, 상수로 남아있는 녀석들\n",
    "    - 그렇기 때문에 일반화를 위해 진행하는 Hyper Parameter Tuning은 매우 중요함\n",
    "    \n",
    "## 1.4.6. 훈련데이터 과소적합\n",
    "- UnderFitting\n",
    "- 모델이 너무 단순할 때\n",
    "- Overfitting의 정 반대로 행동했을 때 발생하며, 반대의 해결책을 제시해야 해결할 수 있는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5. 테스트와 검증\n",
    "- 일반적으로 훈련 데이터를 훈련 세트와 테스트 세트로 나눠서 진행\n",
    "- 새로운 사례들에 대한 오류 비율을 Generalization Error(Out-Of-Sample Error)라고 함\n",
    "    - 이 것을 사전에 줄이기 위해 테스트 세트로 이 오차의 \"추정값\"을 구해보는 것\n",
    "    - 이 추정값이 높다면 모델이 과대적합 되었다고 볼 수 있는 것\n",
    "* 일반적으로 20%정도를 테스트용을 떼놓음\n",
    "- 이렇게 모델이 계속해서 튜닝 될 것인데, 이 때도 실제 서비스 시 문제가 발생하는 경우가 더러 있음\n",
    "    - 이건 테스트용으로 떼놓은 데이터의 결과를 올리려다보니, 테스트 세트가 일종의 훈련 세트가 되어버린 것임\n",
    "- 이런 상황을 방지하기 위하여 Validation Set을 둠\n",
    "    - 이건 단 한 번의 테스트용\n",
    "- 근데, 이렇게 Training, Test, Validation Set을 모두 쪼개면 데이터 손실이 큼\n",
    "    - 그래서 활용하는 것이 Cross Validation(교차검증)\n",
    "    - 훈련 세트를 여러 subset으로 나누고, 각 모델을 이 subset의 조합으로 훈련\n",
    "    - 그리고 훈련에 활용하지 않은 나머지 부분으로 검증함\n",
    "    - 즉, 전체 데이터에서 training과 Test를 떼놓음. 그리고 이 Set을 subset이 10개로\n",
    "        - 그러면, subset하나를 학습시킬 경우 9개의 subset이 남음 - 이걸 Validation Set으로 활용\n",
    "        - 처음에 떼놓은 Test Set은 마지막 딱 한 번만 활용하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
